version: "3"
services:

  labeltool-lite-inference:
    build:
      context: ./inference
      dockerfile: Dockerfile
    image: labeltool.lite.inferance:latest
    networks:
      - labeltool-lite-net
    volumes:
      - "./data/inference-data/models:/models"
      - "./data/inference-data/models_hash:/models_hash"

  labeltool-lite-backend:
    build:
      context: ./backend
      dockerfile: ./Dockerfile
    image: labeltool.lite.backend:latest
    restart: unless-stopped
    networks:
      - labeltool-lite-net
    ports:
      - "8000:80"
    volumes:
      #Windows
      - "D:\\Proyectos\\BMW-Labeltool-Lite\\data\\training-data:/training-data"
      #Linux
      #- "./data/training-data:/training-data"

  labeltool-lite-frontend:
    build:
      context: ./frontend
      dockerfile: ./Dockerfile
    image: labeltool.lite.frontend:latest
    restart: unless-stopped
    networks:
      - labeltool-lite-net
    ports:
      - "8081:80"
    depends_on:
      - labeltool-lite-backend

networks:
  labeltool-lite-net:
